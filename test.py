import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import AdaBoostRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score
from datetime import datetime as dt



from sklearn.ensemble import RandomForestRegressor  # Mod√®le de r√©gression par for√™ts al√©atoires
from sklearn.linear_model import LinearRegression   # Mod√®le de r√©gression lin√©aire
from sklearn.svm import SVR                         # Mod√®le de r√©gression bas√© sur les machines √† vecteurs de support (SVM)
from sklearn.preprocessing import MinMaxScaler      # Outil pour normaliser les donn√©es
from sklearn.metrics import mean_squared_error, r2_score  # M√©triques pour √©valuer les performances des mod√®les
from datetime import datetime as dt                # Biblioth√®que pour travailler avec les dates
# Importation des biblioth√®ques n√©cessaires pour les analyses
from sklearn.preprocessing import StandardScaler  # Pour la normalisation des donn√©es
from sklearn.decomposition import PCA  # Pour la r√©duction de la dimensionnalit√©
from sklearn.model_selection import train_test_split  # Pour diviser les donn√©es en ensembles d'entra√Ænement et de test
from sklearn.linear_model import LogisticRegression  # Pour le mod√®le de r√©gression logistique
from sklearn.metrics import classification_report  # Pour √©valuer les performances du mod√®le
# Titre principal
st.markdown("# üìä Tableau de bord de la pr√©diction de la dur√©e de vie des moteurs")
st.markdown("### Analyse de la performance des moteurs Turbofan √† partir de donn√©es de capteurs")

# Ajout d'une image (optionnelle) - vous pouvez ajouter votre logo ici
# st.image('path_to_logo.png', width=200)

# Menu Lat√©ral
st.sidebar.title("Navigation")
menu_options = ["Aper√ßu des donn√©es", "Analyse des capteurs", "PCA et R√©gression Logistique", "Mod√®les de Pr√©diction"]
selection = st.sidebar.radio("Choisir une section", menu_options)

# Chargement des donn√©es
@st.cache_data
def load_data():
    columns = ['engine', 'cycle', 'setting1', 'setting2', 'setting3'] + [f'sensor{i}' for i in range(1, 22)]
    train_data = pd.read_csv("train_FD001.txt", sep='\\s+', names=columns)
    return train_data

data = load_data()

# Affichage des premi√®res lignes
st.subheader("Aper√ßu des donn√©es")
st.dataframe(data.head())

# Ajout de la colonne RUL
def add_remaining_RUL(data):
    max_cycles = data.groupby('engine')['cycle'].max()
    merged = data.merge(max_cycles.to_frame(name='max_cycles'), left_on='engine', right_index=True)
    merged["RUL"] = merged["max_cycles"] - merged['cycle']
    return merged.drop("max_cycles", axis=1)

data = add_remaining_RUL(data)

# S√©lection d'un moteur
engine_selected = st.selectbox("S√©lectionnez un moteur", data["engine"].unique())
engine_data = data[data["engine"] == engine_selected]

# Recherche du nombre maximum de cycles pour chaque moteur
def find_max_cycle(data):
    st.subheader("Nombre maximum de cycles pour chaque moteur")
    max_cycle = data[['engine', 'cycle']].groupby(['engine']).count().reset_index().rename(columns={'cycle': 'max_cycles'})
    return max_cycle

max_cycle = find_max_cycle(data)
st.dataframe(max_cycle)

# Affichage des graphiques
st.subheader("√âvolution des capteurs et r√©glages au fil des cycles")
fig, axes = plt.subplots(4, 5, figsize=(15, 10), sharex=True)
axes = axes.flatten()
columns_to_plot = ['setting1', 'setting2', 'setting3'] + [f'sensor{i}' for i in range(1, 16)]

for i, col in enumerate(columns_to_plot):
    axes[i].plot(engine_data['cycle'], engine_data[col], label=col)
    axes[i].set_title(col)
    axes[i].legend()
    axes[i].grid(True)

plt.tight_layout()
st.pyplot(fig)

# Affichage du graphique des cycles maximums
def barplt(data):
    fig, ax = plt.subplots(figsize=(15,10))
    sns.barplot(x='engine', y='max_cycles', data=data, palette='coolwarm', ax=ax)
    sns.set_context("notebook")
    ax.set_title('Dur√©e de vie des moteurs Turbofan', fontweight='bold', fontsize=20)
    ax.set_xlabel('Moteurs', fontweight='bold', fontsize=15)
    ax.set_ylabel('Cycles maximum', fontweight='bold', fontsize=15)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, fontsize=10)
    ax.grid(visible=True, linestyle='--', alpha=0.7)
    plt.tight_layout()
    st.pyplot(fig)

barplt(max_cycle)

# Analyse des relations entre deux variables (nuages de points)
st.subheader("Relation entre op_setting_1 et op_setting_2")
fig_scatter = plt.figure(figsize=(10, 8))
sns.scatterplot(
    data=data, 
    x='setting1', 
    y='setting2', 
    hue='setting3', 
    style='setting3', 
    palette='coolwarm',
    s=100,
    edgecolor='black',
    alpha=0.8
)
plt.title('Relation entre op_setting_1 et op_setting_2', fontweight='bold', fontsize=16, color='darkgreen')
plt.xlabel('op_setting_1', fontweight='bold', fontsize=14, color='navy')
plt.ylabel('op_setting_2', fontweight='bold', fontsize=14, color='navy')
plt.legend(title='Setting 3', fontsize=12, title_fontsize=14)
plt.grid(visible=True, linestyle='--', alpha=0.6)
st.pyplot(fig_scatter)

# Distribution des RUL
st.subheader("Distribution de la dur√©e de vie restante (RUL)")
fig_rul = plt.figure(figsize=(10, 5))
sns.histplot(data['RUL'], kde=True, bins=20, color='blue')
plt.title("Distribution du RUL")
st.pyplot(fig_rul)
# Fonction pour afficher une matrice de corr√©lation sous forme de carte thermique
def corr_matrix(data):
    fig, ax = plt.subplots(figsize=(12, 8))  # Taille ajust√©e pour une meilleure lisibilit√©
    
    # Contexte ajust√© pour un rendu clair des polices
    sns.set_context("notebook", font_scale=1.2)  # Taille des polices augment√©e
    
    # Carte thermique de la matrice de corr√©lation
    sns.heatmap(
        data.corr(), 
        annot=True,                # Affiche les valeurs num√©riques sur la carte
        fmt=".2f",                 # Format des nombres affich√©s
        cmap='coolwarm',           # Palette personnalis√©e pour une meilleure lecture
        linewidths=0.5,            # Ajout de lignes fines entre les cellules
        linecolor='gray',          # Couleur des lignes pour d√©limiter les cellules
        cbar_kws={'shrink': 0.8},  # R√©duction de la taille de la barre de couleur
        ax=ax
    )
    
    # Titre de la matrice de corr√©lation
    ax.set_title('Matrice de corr√©lation', fontweight='bold', fontsize=16, color='darkblue')
    
    # Ajustement des marges pour √©viter que les √©l√©ments soient coup√©s
    plt.tight_layout()

    return fig  # Retourne l'objet fig pour l'utiliser avec st.pyplot()

# Appelle la fonction pour afficher la matrice de corr√©lation
fig = corr_matrix(data)
st.pyplot(fig)  # Affiche la figure g√©n√©r√©e


def clean_data(train_data, test_data):
    # Liste des colonnes √† supprimer
    cols_to_drop = ['setting1', 'setting2', 'sensor6', 'sensor5', 'sensor16', 'setting3', 'sensor1', 'sensor10', 'sensor18', 'sensor19']
    
    # Filtrer les colonnes existantes dans le DataFrame
    existing_cols_to_drop = [col for col in cols_to_drop if col in train_data.columns]
    
    # Supprimer les colonnes existantes dans le DataFrame
    cleaned_train = train_data.drop(existing_cols_to_drop, axis=1)
    cleaned_test = test_data.drop(existing_cols_to_drop, axis=1)
    
    return cleaned_train, cleaned_test

# Exemple d'appel de la fonction avec tes donn√©es
data = pd.read_csv('train_FD001.txt', sep=' ')  # Assure-toi que tes donn√©es sont correctement charg√©es
clean_train_data, clean_test_data = clean_data(data, data)  # Appliquer le nettoyage ici

# Afficher les r√©sultats nettoy√©s pour v√©rifier
print(clean_train_data.head())
# Dictionnaire de noms de capteurs pour la visualisation
sens_names = {
    'sensor2': '(Temp√©rature de sortie LPC) (‚ó¶R)',
    'sensor3': '(Temp√©rature de sortie HPC) (‚ó¶R)',
    'sensor4': '(Temp√©rature de sortie LPT) (‚ó¶R)',
    'sensor7': '(Pression de sortie HPC) (psia)',
    'sensor8': '(Vitesse physique du ventilateur) (rpm)',
    'sensor9': '(Vitesse physique du c≈ìur) (rpm)',
    'sensor11': '(Pression statique de sortie HPC) (psia)',
    'sensor12': '(Rapport de d√©bit de carburant √† Ps30) (pps/psia)',
    'sensor13': '(Vitesse corrig√©e du ventilateur) (rpm)',
    'sensor14': '(Vitesse corrig√©e du c≈ìur) (rpm)',
    'sensor15': '(Rapport de d√©rivation) ',
    'sensor17': '(Enthalpie de saign√©e)',
    'sensor20': '(D√©bit d‚Äôair de refroidissement des turbines √† haute pression)',
    'sensor21': '(D√©bit d‚Äôair de refroidissement des turbines √† basse pression)'
}

# Fonction pour afficher les courbes de chaque capteur
def plot_sensor(sensor_name, sens_names, data):
    for S in sensor_name:
        if S in data.columns:
            plt.figure(figsize=(13, 5))
            for i in data['engine'].unique():
                if (i % 5 == 0):
                    plt.plot('RUL', S, data=data[data['engine'] == i].rolling(8).mean())
            plt.xlim(250, 0)
            plt.xticks(np.arange(0, 275, 25))
            plt.ylabel(sens_names[S])
            plt.xlabel('Dur√©e de vie utile restante (RUL)')
            plt.grid(True)
            plt.show()

# Charger les donn√©es
columns = ['unit', 'time', 'op_setting_1', 'op_setting_2', 'op_setting_3'] + [f'sensor_{i}' for i in range(1, 22)]
@st.cache
def load_data():
    # Remplace par le chemin d'acc√®s √† ton fichier
    data = pd.read_csv("train_FD001.txt", delim_whitespace=True, header=None, names=columns)
    return data

data = load_data()

# Calculer la RUL
data['RUL'] = data.groupby('unit')['time'].transform(max) - data['time']

# Cr√©er le label binaire
threshold = 50
data['label'] = (data['RUL'] <= threshold).astype(int)

# Interface utilisateur Streamlit
st.title('Analyse des moteurs Turbofan')
st.markdown('### Visualisation de la dur√©e de vie restante (RUL) des moteurs')

# Nettoyage des donn√©es
st.sidebar.header("S√©lection des Capteurs")
sensor_col = st.sidebar.multiselect("Choisir les capteurs", list(sens_names.keys()), default=list(sens_names.keys()))
clean_train_data, clean_test_data = clean_data(data, data)  # On applique le nettoyage ici

# Affichage des graphiques des capteurs choisis
if len(sensor_col) > 0:
    st.write("### Courbes de capteurs s√©lectionn√©s")
    plot_sensor(sensor_col, sens_names, clean_train_data)

# R√©duction de la dimensionnalit√© avec PCA
st.markdown('### Analyse PCA (R√©duction de la dimensionnalit√©)')
scaler = StandardScaler()
sensor_columns = [f'sensor_{i}' for i in range(1, 22)]
data_scaled = scaler.fit_transform(data[sensor_columns])

pca = PCA(n_components=5)
data_pca = pca.fit_transform(data_scaled)

for i in range(data_pca.shape[1]):
    data[f'PC{i+1}'] = data_pca[:, i]

# Diviser les donn√©es
X = data[[f'PC{i+1}' for i in range(5)]]
y = data['label']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Mod√®le de r√©gression logistique
st.markdown('### Entra√Ænement du mod√®le de r√©gression logistique')
model = LogisticRegression()
model.fit(X_train, y_train)

# Pr√©dictions et √©valuation
y_pred = model.predict(X_test)
classification_rep = classification_report(y_test, y_pred)
st.text(classification_rep)

# Visualisation des deux premi√®res composantes principales
st.markdown('### Visualisation des deux premi√®res composantes principales')
plt.figure(figsize=(10, 6))
scatter = plt.scatter(data_pca[:, 0], data_pca[:, 1], c=data['label'], cmap='viridis', alpha=0.7, edgecolor='k')
plt.colorbar(scatter, label='Label (0 = Normal, 1 = Critique)')
plt.xlabel('Composante principale 1')
plt.ylabel('Composante principale 2') 
plt.title('Visualisation PCA avec classes')
plt.grid(True, linestyle='--', alpha=0.6)
st.pyplot(plt)

 


# Importation des biblioth√®ques
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, r2_score
from datetime import datetime as dt

# Configuration de pandas
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)

# D√©finition des colonnes du dataset
eng_cycle_col = ['engine', 'cycle']
setting_col = ['setting1', 'setting2', 'setting3']
sensor_col = [f'sensor{i}' for i in range(1, 22)]
columns = eng_cycle_col + setting_col + sensor_col

# Importation des donn√©es
train_data = pd.read_csv("train_FD001.txt", sep='\\s+', names=columns)
test_data = pd.read_csv("test_FD001.txt", sep='\\s+', names=columns)
true_rul = pd.read_csv("RUL_FD001.txt", sep='\\s+', names=['RUL'])

# Fonction pour ajouter la colonne "RUL"
def add_remaining_RUL(data):
    max_cycles = data.groupby('engine')['cycle'].max()
    merged = data.merge(max_cycles.to_frame(name='max_cycles'), left_on='engine', right_index=True)
    merged["RUL"] = merged["max_cycles"] - merged['cycle']
    return merged.drop("max_cycles", axis=1)

# Ajout de la colonne "RUL"
train_data = add_remaining_RUL(train_data)

# Suppression des colonnes inutiles pour l'entra√Ænement
cols_to_drop = ['engine', 'cycle']
clean_train_data = train_data.drop(cols_to_drop, axis=1)

# Normalisation des donn√©es d'entra√Ænement
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(clean_train_data.drop('RUL', axis=1))
scaled_data = pd.DataFrame(scaled_data, columns=clean_train_data.drop('RUL', axis=1).columns)

# S√©paration des features (X) et de la cible (Y)
X_train = scaled_data
Y_train = train_data['RUL']

# Pr√©paration des donn√©es de test
X_test = test_data.groupby('engine').last().reset_index()
X_test = X_test.drop(['setting1', 'setting2', 'sensor6', 'sensor5', 'sensor16',
                      'setting3', 'sensor1', 'sensor10', 'sensor18', 'sensor19'], axis=1)

scaled_test_data = scaler.transform(X_test.drop(['engine', 'cycle'], axis=1))
scaled_test_data = pd.DataFrame(scaled_test_data, columns=X_test.drop(['engine', 'cycle'], axis=1).columns)

Y_test = true_rul['RUL']
X_train_s = X_train
X_test_s = scaled_test_data

# Fonction d'√©valuation du mod√®le
def evaluate(y_true, y_hat, label='test'):
    mse = mean_squared_error(y_true, y_hat)
    rmse = np.sqrt(mse)
    variance = r2_score(y_true, y_hat)
    print('{} set RMSE: {:.2f}, R2: {:.2f}'.format(label, rmse, variance))

# TEST 1: R√©gression Lin√©aire
start_1 = dt.now()
lm = LinearRegression()
lm.fit(X_train_s, Y_train)
Y_predict_train = lm.predict(X_train_s)
Y_predict_test = lm.predict(X_test_s)

print('√âvaluation de la R√©gression Lin√©aire:')
print('Le temps d\'ex√©cution est de : {}s'.format((dt.now() - start_1).seconds))

evaluate(Y_train, Y_predict_train, 'train')
evaluate(Y_test, Y_predict_test)

# Affichage de la courbe de la pr√©diction
plt.figure(figsize=(18, 10))
plt.plot(Y_test.values, color='red', label='RUL r√©el')
plt.plot(Y_predict_test, label='Pr√©diction R√©gression Lin√©aire')
plt.legend(loc='upper left')
plt.grid(True)
plt.show()

# TEST 2: Arbre de D√©cision (Random Forest)
start_2 = dt.now()  # Enregistrement du temps de d√©but pour l'arbre de d√©cision
rf = RandomForestRegressor(max_features="sqrt", random_state=42)  # Initialisation du mod√®le Random Forest
rf.fit(X_train_s, Y_train)  # Entra√Ænement du mod√®le avec les donn√©es d'entra√Ænement
Y_predict_train_rf = rf.predict(X_train_s)  # Pr√©dictions sur les donn√©es d'entra√Ænement
Y_predict_test_rf = rf.predict(X_test_s)  # Pr√©dictions sur les donn√©es de test

# Affichage du score du mod√®le Random Forest et du temps d'ex√©cution
print('√âvaluation du mod√®le Random Forest Regressor: ')
print('Le temps d\'ex√©cution est de : ' + str((dt.now() - start_2).seconds) + 's')

# √âvaluation du mod√®le Random Forest en utilisant la fonction `evaluate`
evaluate(Y_train, Y_predict_train_rf, 'train')  # √âvaluation des pr√©dictions sur les donn√©es d'entra√Ænement
evaluate(Y_test, Y_predict_test_rf)  # √âvaluation des pr√©dictions sur les donn√©es de test

# Affichage de la courbe de la pr√©diction de l'arbre de d√©cision
plt.plot(Y_predict_test_rf, color='orange', label='Pr√©diction Random Forest')  # Courbe de la pr√©diction
plt.legend(loc='upper left')
plt.grid(True)

# TEST 3: Machine √† Vecteurs de Support (SVM)
start_3 = dt.now()  # Enregistrement du temps de d√©but pour le mod√®le SVM
svm = SVR(kernel='linear')  # Initialisation du mod√®le SVM avec noyau lin√©aire
svm.fit(X_train_s, Y_train)  # Entra√Ænement du mod√®le avec les donn√©es d'entra√Ænement
svm_train_prediction = svm.predict(X_train_s)  # Pr√©dictions sur les donn√©es d'entra√Ænement
svm_test_predict = svm.predict(X_test_s)  # Pr√©dictions sur les donn√©es de test

# Affichage du score du mod√®le SVM et du temps d'ex√©cution
print('√âvaluation du mod√®le Support Vector Machine: ')
print('Le temps d\'ex√©cution est de : ' + str((dt.now() - start_3).seconds) + 's')

# √âvaluation du mod√®le SVM en utilisant la fonction `evaluate`
evaluate(Y_train, svm_train_prediction, 'train')  # √âvaluation des pr√©dictions sur les donn√©es d'entra√Ænement
evaluate(Y_test, svm_test_predict)  # √âvaluation des pr√©dictions sur les donn√©es de test

# Affichage de la courbe de la pr√©diction SVM
plt.plot(svm_test_predict, color='black', label='Pr√©diction SVM')  # Courbe de la pr√©diction SVM
plt.legend(loc='upper left')
plt.grid(True)

# Affichage de toutes les courbes
plt.show()
st.pyplot(fig)



